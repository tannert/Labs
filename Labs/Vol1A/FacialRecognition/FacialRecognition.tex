\lab{Facial Recognition Using Eigenfaces}{Facial Recognition Using Eigenfaces}
\label{lab:FacialRecognition}

\objective{Use the singular value decomposition to implement a simple facial recognition system.}

Suppose we have a large database containing images of human faces.
We would like to identify people by comparing their pictures to those in the database.
This task is called \emph{facial recognition}.

One way to automate the comparison process is know as the \emph{eigenfaces} method.
As the name suggests, this method uses eigenvectors of matrices related to the collection of face images.
The method essentially projects face images to a low-dimensional subspace, in a way that preserves their distinguishing characteristics.
Comparing the images in fewer dimensions is faster and allows us to store the images using less data.

The idea of projecting to fewer dimensions is not unique to the eigenfaces method.
This method is an example of \emph{principal component analysis}, where data is compared based on its principal components in a lower-dimensional vector space.
Principal component analysis can be applied to many computing problems besides facial recognition.
% TODO: list 2-3 other applications

\begin{comment}
Facial recognition is important in law enforcement, as well as other situations. 
For example, facial recognition can be combined with video surveillance to identify when a person is not authorized to be in a location.

Humans can easily compare two face images and determine whether they belong to the same person, but automating this process is more challenging.
One technique for automated facial recognition uses \emph{eigenfaces}.
\end{comment}

\section*{Load the Data}
\begin{comment}
Eigenfaces are an efficient way to store and query a database of face images.
As the name suggests, this method uses eigenvectors of matrices related to the collection of face images.
Essentially, the method of eigenfaces projects face images to a lower-dimensional subspace in a way that preserves their distinguishing characteristics. 
In the lower-dimensional subspace, comparing face images is much faster.
\end{comment}

The first step is to obtain a dataset of face images.
Recall that a digital image may be stored as an $m \times n$ array of pixels. 
In this lab, we will store the images as $mn$-vectors by concatenating the rows of the $m \times n$ arrays.

\begin{problem}
\label{prob:getTrainingFaces}
In this lab we will use the \li{faces94} face image dataset found at \url{http://cswww.essex.ac.uk/mv/allfaces/faces94.html} 
This problem will make sure that you can load and display the images from the dataset.
\begin{enumerate}
\item Download the \li{faces94} dataset from the link above and extract the files.
You should now have a directory named ``faces94" which contains photographs of 153 people, organized into folders by person.

\item The function \li{getFaces()} is given in the appendix. %or spec file?
It constructs a set of face images by selecting exactly one face image for each person in the directory.
It should return an array whose columns are flattened face images.
Feel free to modify the given code.
You may have to replace the parameter \li{\"./faces94\"} with the location of the directory \li{faces94} on your machine.

Test this function to make sure it runs without errors.
Check that the return value \li{F} is a $36000 \times 153$ array. 
The columns of this array are 153 flattened face images of 153 different people.

\item Use \li{plt.imshow()} to display one of the faces.
The original image dimensions are $200 \times 180$.
You may find it useful to write a helper function that accepts a flattened image and displays it.

\end{enumerate}
\end{problem}


\section*{Shift By the Mean}

The facial recognition algorithm is more robust if we first \emph{shift by the mean}. When we shift a set of data by the mean, the distinguishing features are exaggerated. Therefore, in the context of facial recognition, shifting by the mean accentuates the unique features of the face.
Suppose we have a collection of $k$ face images represented as vectors $\f_1, \f_2, \ldots, \f_k$ of length $mn$.
Define the \emph{mean face} ${\boldsymbol \mu}$ to be the average of the $\f_i$:
\[
{\boldsymbol \mu} = \frac{1}{k}\sum_{i=1}^k \f_i.
\]
\begin{figure}
\includegraphics[width=0.3\textwidth]{meanFace.png}
\caption{The mean face.}
\label{facialRecognition:meanFace}
\end{figure}

\begin{problem}
\label{prob:meanFace}
\leavevmode

The facial recognition method you will write in this lab will be structured as a class. 
An outline of the \li{FacialRec} class is provided in the appendix. %or maybe in the spec file?
You will write the methods of the class.

When initialized, the \li{FacialRec} object first loads the face images using \li{getFaces} and stores the result.
The next step is to compute the mean face.
\begin{enumerate}
\item In your class definition, implement the method \li{FacialRec.initMeanImage()}.
Compute the mean face and store it as \li{self.mu}.
This can be done in one line of code using NumPy.

\item Display the mean face.
Your result should match Figure \ref{facialRecognition:meanFace}.
\end{enumerate}
\end{problem}



\begin{figure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{differenceFace0.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{differenceFace1.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{differenceFace2.png}
\end{subfigure}
\caption{Three mean-shifted faces from the dataset.}
\label{facialRecognition:differenceFaces}
\end{figure}
For each $i = 1,\ldots, k$, define $\bar{\f}_i := \f_i - {\boldsymbol \mu}$.
The mean-shifted face vector $\bar{\f}_i$ is the deviation of the $i$-th face from the mean, and thus captures the unique features of the face.
Now form the $mn \times k$ matrix $\bar{F}$ whose columns are given by the mean-shifted face vectors, i.e.
\[
\bar{F} = \begin{bmatrix}
\bar{\f}_1 & \bar{\f}_2 & \cdots & \bar{\f}_k
\end{bmatrix}.
\]
\begin{problem}
\leavevmode
\begin{enumerate}
\item In your class definition, implement the method \li{FacialRec.initDifferences()}.
Compute $\bar{F}$ and store it as \li{self.Fbar}.
This can be done in one line using array broadcasting.
\item
Display one of the mean-shifted faces. 
The output should be similar to the faces in Figure \ref{facialRecognition:differenceFaces}.
\end{enumerate}
\end{problem}


\section*{Project to a Subspace}
Now suppose we are given a new face vector $\g$. 
We first shift $\g$ by the mean of the dataset, giving us $\bar{\g} = \g - {\boldsymbol \mu}$.
The closest match to $\bar{\g}$ is the vector $\bar{\f}_i$ that minimizes $\|\bar{\g}-\bar{\f}_i\|_2$.
If there are $k$ images in the dataset, we find this match by comparing $\bar{\g}$ to every element of $\{\bar{\f}_1, \ldots \bar{\f}_k\}$.

However, comparing the original face images pixel by pixel is computationally expensive and inefficient.
The vectors $\bar{\f}_i$ and $\bar{\g}$ are length $mn$, which in our case equals 36000 and in practice may be many times larger.
Computing the difference between face vectors of this length is time consuming, especially when the dataset is very large.
It also requires us to use $mn$ values to store each face, which is an inefficient use of space.
In addition, pixel by pixel comparison is not very robust to small changes in individual pixels.

Instead, in order to store and compare our face vectors, we would like to represent each one with fewer than $mn$ values.
We can do this by projecting to a subspace.
Mathematically, we want to choose $s$, $s \ll mn$, and project the face vectors to an $s$-dimensional subspace of the original $mn$-dimensional space of images.
We can then use just $s$ values to store each face in terms of the basis vectors of the new subspace.

The ``best" subspace to project to is the one that is closest in the least squares sense (i.e., such that the sum of the squared errors between $\{\bar{\f}_1, \ldots \bar{\f}_k\}$ and their projections is minimized).
Let $U \Sigma V^T$ be an SVD of $\bar{F}$, with $\u_i$ the columns of $U$. 
As we will prove below, the $s$-dimensional subspace that minimizes the squared error is the span of $\u_1, \ldots, \u_s$.
Note that $\u_1, \ldots, \u_s$ is an orthonormal basis for this subspace.

The projection matrix is $P_s = U_s U_s^T$ where $U_s = [ \u_1\; \ldots \; \u_s]$. 
%The matrix for the projection is $P_s = U_s U_s^T$ where $U_s$ is the first $s$ columns of $U$. 
This matrix projects the original face vectors into the optimal $s$-dimensional subspace. 

\begin{comment}
\section*{Project to a Subspace, Old Version}
Now suppose we have a new face vector $\g$. 
The closest face image to $\g$ should be the vector $\bar{\f}_i$ that minimizes $\|\bar{\g}-\bar{\f}_i\|_2$, where $\bar{\g} = \g - {\boldsymbol \mu}$.
Unfortunately, computing $\|\bar{\g}-\bar{\f}_i\|_2$ for each $i$ is computationally intractable when the length $mn$ of the vectors is large.
Since a low-resolution photo may easily have $100\times 100 = 10,000$ pixels, in practice $mn$ is very large indeed.

Here is the trick: instead of computing in the $mn$-dimensional space of all possible images, we will compute in a lower-dimensional subspace.
We could start by using the subspace spanned by the vectors $\bar{\f}_1, \ldots \bar{\f}_k$, which is at most $k$-dimensional. 
Unfortunately, in practice $k$ is still too large for this subspace to be computationally efficient.
%We need to project our problem into some subspace of the span of $\bar{\f}_1, \ldots \bar{\f}_k$.

Therefore, we want to project to a subspace of $\bar{\f}_1, \ldots \bar{\f}_k$ in a way that retains as much information about the $\bar{\f_i}$ as possible.
Mathematically, we want to find the $s$-dimensional subspace of $\text{span}\{\bar{\f}_1, \ldots \bar{\f}_k\}$ that is closest to the $\bar{\f_i}$ in the least-squares sense.
In a minute, we will prove that the SVD of $\bar{F}$ (whose columns are $\bar{\f}_1, \ldots \bar{\f}_k$) solves this problem.
But first, let us summarize how the solution works.

Let $U \Sigma V^T$ be an SVD of $\bar{F}$ with $\u_i$ the columns of $U$. 
Then the ``best'' $s$-dimensional subspace for approximating $\text{span}\{\bar{\f}_1, \ldots \bar{\f}_k\}$ is the span of $\u_1, \ldots, \u_s$. 
The matrix for this projection is $P_s = U_s U_s^T$ where $U_s = [ \u_1\; \ldots \; \u_s]$.

Because the vectors $\u_i$ are eigenvectors of $\bar{F}\bar{F}^T$, we call them \emph{eigenfaces}. 
Therefore, the best $s$-dimensional subspace for solving the facial recognition problem is exactly the span of the first $s$ eigenfaces.
\end{comment}

\subsection*{The Proof: SVD as a Least Squares Solution}
\begin{theorem}
Let $\f_1, \ldots, \f_k$ be vectors on $\mathbb{R}^{mn}$, and let $\bar{F} = [\bar{f}_1 \; \ldots \; \bar{f}_k]$. Suppose $U\Sigma V^T$ is an SVD for $\bar{F}$. Then the $s$-dimensional subspace that solves the least squares problem for $\f_1, \ldots, \f_k$ is the span of the first $s$ columns of $U$. If $U_s$ is the first $s$ columns of $U$, then the matrix $U_sU_s^T$ is projection onto this subspace.
\end{theorem}
\begin{proof}
We seek a rank-$s$ projection matrix $P_s$ so that $\sum_{i=1}^k \|P_s\bar{\f}_i - \bar{\f}_i\|_2^2$ is minimized---i.e.,
 the sum of the squares of the ``errors'' is minimal when we project $\bar{\f}_i$ via $P_s$.
 But minimizing this quantity is the same as minimizing its square, which happens to equal the Frobenius norm of $P_s\bar{F} - \bar{F}$. 
Written mathematically,
 \begin{align*}
\inf_{\text{rank}(P_s)=s} \sum_{i=1}^k \|P_s\bar{\f}_i - \bar{\f}_i\|_2^2 &=  \inf_{\text{rank}(P_s)=s} \left( \sum_{i=1}^k \|P_s\bar{\f}_i - \bar{\f}_i\|_2^2 \right) ^2\\
 & =  \inf_{\text{rank}(P_s)=s} \| P_s\bar{F}-\bar{F}\|_F.
 \end{align*}
 
Now let $U \Sigma V^T$ be an SVD of $\bar{F}$ with $\u_i$ the columns of $U$, $\v_i$ the columns of $V$, and $\sigma_i$ the singular values of $\bar{F}$.
If $P_s = \sum_{i=1}^s \u_i \u_i^T$, then 
\begin{align*}
P_s\bar{F} &=  \left( \sum_{i=1}^s \u_i \u_i^T \right)\left(  \sum_{j=1}^k \sigma_j \u_i \v_i^T \right)
= \sum_{i=1}^s\sum_{j=1}^k \sigma_j \u_i\u_i^T\u_j\v_j^T\\
&=  \sum_{i=1}^s\sum_{j=1}^k \sigma_j \u_i\delta_{ij}\v_j^T
= \sum_{i=1}^s \sigma_i \u_i\v_i^T.
\end{align*}

In fact, the Schmidt-Eckart-Young-Mirsky Theorem from Lab \ref{lab:SVD} tells us that $X = \sum_{i=1}^s \sigma_i \u_i\v_i^T$ is exactly the rank-$s$ matrix that minimizes $\|X - \bar{F}\|_F$. 
Since $P_s \bar{F}$ will always have rank $s$ or less, the projection $P_s =  \sum_{i=1}^s \u_i \u_i^T$ is the one we seek.
If we let $U_s = [ \u_1\; \ldots \; \u_s]$, then we may write $P_s = U_sU_s^T$. Notice that $P_s$ is projection onto the subspace spanned by the columns of $U_s$.
\end{proof}

The $s$ basis vectors $\u_1, \ldots, \u_s$ are eigenvectors of $\bar{F}\bar{F}^T$.
They also resemble face images.
Hence they are commonly called the ``eigenfaces." 

\begin{problem}
\label{prob:svd}
\leavevmode
\begin{enumerate}
\item In your class definition, implement the method \li{FacialRec.initEigenfaces()}.

Compute the SVD (\li{scipy.linalg.svd()} is a good implementation to use) and store the array \li{U} containing the eigenfaces as its columns.
Because we will only use the first few columns of \li{U}, specify the keyword parameter \li{full_matrices=False} to compute only the compact SVD.
\item Plot the first eigenface (i.e. the first column of \li{U}).
It should resemble the first eigenface shown in Figure \ref{facialRecognition:eigenfaces}.
\end{enumerate}
\end{problem}

\section*{Change Basis}

The projection matrix $P_s = U_s U_s^T$ projects a face vector into the $s$-dimensional subspace spanned by the eigenfaces, but still keeps it as a vector in $\mathbb{R}^{mn}$. 
The change-of-basis matrix $U_s^T$ both projects the face vector and and changes the basis.
The resulting vector has length $s$ and represents the face in terms of eigenfaces.

To represent any face vector in terms of the first $s$ eigenfaces, multiply by $U_s^T$. 
To change back to a full length-$mn$ projection, multiply again by $U_s$.

\begin{comment}
It does us no good to project all our vectors into an $s$-dimensional space if we still store them as vectors in $\mathbb{R}^{nm}$. 
Instead, we must store our face vectors in terms of the columns of $U_s$.
This way, each vector is a length-$s$ array in NumPy, instead of a length-$mn$ array.

The change-of-basis matrix is $U_s^T$, so $U_s^TP_s = U_s^TU_sU_s^T = U_s^T$. 
Thus we can project into the subspace and change basis by multiplying by $U_s^T$.
To change back to the full $mn$-vector, multiply by $U_s$.
\end{comment}


\begin{figure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{eigenface0.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{eigenface1.png}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{eigenface2.png}
\end{subfigure}
\caption{The top three eigenfaces.}
\label{facialRecognition:eigenfaces}
\end{figure}



\begin{problem}
\label{prob:top_n}
\leavevmode
\begin{enumerate}
\item Implement the method  \li{FacialRec.project()} in your class definition.
This should accept a flattened image or an array with flattened images as its columns.
It should also accept a value for $s$. 
The function should project the image or images into the appropriate $s$-dimensional subspace and change basis, then return the result.
\item Let \li{face} be the first mean-shifted face (the first column of \li{facialRec.Fbar}). Do the following:
\begin{enumerate}
\item Project \li{face} so that it is represented in terms of the first 19 eigenfaces.
\item Change basis again back to the standard basis on $\mathbb{R}^{mn}$.
\item Add back the mean face \li{facialRec.mu}.
\item Plot the resulting image.
\end{enumerate}
Your image should match Figure \ref{fig:75_efaces}.
\end{enumerate}
\end{problem}


\begin{figure}

\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltThirtySecond.png}
\caption{5 eigenfaces, about 1/32 of the total.}
\label{fig:5_efaces}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltSixteenth.png}
\caption{9 eigenfaces, or 1/16 of the total.}
\label{fig:9_efaces}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltEighth.png}
\caption{19 eigenfaces, about 1/8 of the total.}
\label{fig:19_efaces}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltFourth.png}
\caption{38 eigenfaces, about 1/4 of the total.}
\label{fig:38_efaces}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltHalf.png}
\caption{75 eigenfaces, about 1/2 of the total.}
\label{fig:75_efaces}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{rebuiltAll.png}
\caption{All 153 of the eigenfaces.}
\label{fig:all_efaces}
\end{subfigure}
\caption{Image rebuilt with various numbers of eigenfaces. The image is somewhat recognizable when it is reconstructed with only 1/8 of the eigenfaces.}
\label{fig:rebuiltImage}
\end{figure}

\begin{comment}
Of course, moving to a lower-dimensional subspace by using only the top $n$ eigenfaces introduces some error, in the sense that we cannot perfectly
reconstruct the face images from their coordinate vectors.
However, this error is tolerable, provided $n$ is not \emph{too} small.
Note that we can approximately reconstruct $\bar{f}_i$ from the coordinate vector $\hat{f}_i$ by
\[
\bar{f}_i \approx U_n\hat{f}_i.
\]
See Figure \ref{facialRecognition:rebuiltImage} for examples of reconstructed face images giving different numbers of eigenfaces.
\end{comment}

\section*{Match Faces}
Finally, we are ready to identify which mean-shifted image $\bar{\f}_i$ is closest to an inputed image, $\bar{\g}$. 
We begin by projecting all vectors to some $s$-dimensional subspace and writing them in terms of the basis vectors, which are the eigenfaces. 
This is done by multiplying by the change-of-basis matrix:
\[
\widehat{\f}_i = U_s^T(\f_i-{\boldsymbol \mu}) \qquad \widehat{\g} = U_s^T(\g-{\boldsymbol \mu}).
\]

Next, we compute which $\widehat{\f}_i$ is closest to $\widehat{\g}$. 
Since the columns of $U_s$ are an orthonormal basis, we get the same result doing the computation in this basis as we would in the standard Euclidean basis.
Define
\[
i^* = \text{argmin}_i \|\widehat{\f}_i - \widehat{\g}\|_2.
\]
Then the $i^*$-th face image is the best match for $\g$.

\begin{problem}
\label{prob:nearest}
\leavevmode
\begin{enumerate}
\item
Implement the method \li{FacialRec.findNearest()} as follows.
\begin{lstlisting}
def findNearest(self, image, s=38):
    Fhat = # Project Fbar, producing a matrix whose columns are the f-hat defined above 
    ghat = # Shift 'image' by the mean and project, producing g-hat as defined above
    # for both Fhat and ghat, use your project function from the previous problem
    
    # Return the index that minimizes ||fhat_i - ghat||_2.
\end{lstlisting}
The functions \li{np.linalg.norm()} and \li{np.argmin()} will be useful for the last line. When using \li{np.linalg.norm}, make sure you indicate the correct axis. 

\item Test your facial recognition system on faces selected randomly from the \li{faces94} dataset.
The function \li{sampleFaces(n_tests, path)} at the end of this lab will build an array of \li{n_tests} random faces from the \li{faces94} dataset.

Plot the random face beside the face returned by your facial recognition code to see if your system is accurately recognizing faces.
%The function \li{show2()} at the end of this lab will plot two face vectors side-by-side.

\end{enumerate}
\end{problem}


By this point, you have created a basic facial recognition system.
We can extend the system to detect when a face doesn't match anything currently in the dataset, and then add this new face.
We can also make the system more robust by including multiple pictures of the same face with different expressions and lighting conditions.

Although there are other approaches to facial recognition that utilize more complex techniques, the method of eigenfaces remains
a wonderfully simple and effective solution, illustrating another application of the singular value decomposition.

\section*{Appendix: Helper Code}
This section contains some functions to help you code up the facial recognition class outlined in the problems of this lab.

\begin{lstlisting}
import numpy as np
from scipy import linalg as la
from os import walk
from scipy.ndimage import imread
from matplotlib import pyplot as plt
from random import sample

def getFaces(path="./faces94"):
    """Traverse the directory specified by 'path' and return an array containing
    one column vector per subdirectory.
    
    For the faces94 dataset, this gives an array with just one column for each
    face in the dataset. Each column corresponds to a flattened grayscale image.
    """
    
    # Traverse the directory and get one image per subdirectory.
    faces = []
    for (dirpath, dirnames, filenames) in walk(path):
        for f in filenames:
            if f[-3:]=="jpg": # only get jpg images
                # load image, convert to grayscale, flatten into vector
                face = imread(dirpath+"/"+f).mean(axis=2).ravel() 
                faces.append(face)
                break
        
    # put all the face vectors column-wise into a matrix.
    F = np.array(faces).T
    return F


def sampleFaces(n_tests,path = "./faces94")
    """Return an array containing a sample of n_tests images contained 
    in the path as flattened images in the columns of the output.
    """
    files = []
    for (dirpath, dirnames, filenames) in walk(path):
        for f in filenames:
            if f[-3:]=="jpg": # only get jpg images
            files.append(dirpath+"/"+f)
            
    #Get a sample of the images
    test_files = sample(files, n_tests)
    #Flatten and average the pixel values
    images = np.array([imread(f).mean(axis=2).ravel() for f in test_files]).T
    return images
    
\end{lstlisting}

The following is the outline of the Facial Recognition class.

\begin{lstlisting}
class FacialRec:
    ##########Members##########
    #   F, mu, Fbar, and U 
    ###########################
    def __init__(self,path):
        self.initFaces(path)
        self.initMeanImage()
        self.initDifferences()
        self.initEigenfaces()

    def initFaces(self, path):
        self.F = getFaces(path)
    def initMeanImage(self):
        pass
    def initDifferences(self):
        pass
    def initEigenfaces(self):
        pass
    def project(self, A, s=38):
        pass
    def findNearest(self, image, s=38):
        pass
\end{lstlisting}
